
 [ALNS17] A. Agarwal, H. Luo, B. Neyshabur, and R. E. Schapire (2017). Corralling a Band of
          Bandit Algorithms. pages 12--38. PMLR.
          [ bib ]
  [Agr95] R. Agrawal (1995). Sample mean based index policies by O(logn) regret for the
          Multi-Armed Bandit problem. Advances in Applied Probability, 27(04):1054--1078.
          [ bib ]
  [AFM17] R. Allesiardo, R. Féraud, and O.-A. Maillard (2017). The Non-Stationary Stochastic
          Multi-Armed Bandit Problem. International Journal of Data Science and Analytics, 3
          (4):267--283.
          [ bib ]
 [AMTA11] A. Anandkumar, N. Michael, A. K. Tang, and S. Agrawal (2011). Distributed
          Algorithms for Learning and Cognitive Medium Access with Logarithmic Regret. IEEE
          Journal on Selected Areas in Communications, 29(4):731--745.
          [ bib ]
 [AVW87a] V. Anantharam, P. Varaiya, and J. Walrand (1987). Asymptotically efficient
          allocation rules for the Multi-Armed Bandit problem with multiple plays - Part I:
          IID rewards. IEEE Transactions on Automatic Control, 32(11):968--976.
          [ bib ]
 [AVW87b] V. Anantharam, P. Varaiya, and J. Walrand (1987). Asymptotically efficient
          allocation rules for the Multi-Armed Bandit problem with multiple plays - Part II:
          Markovian rewards. IEEE Transactions on Automatic Control, 32(11):977--982.
          [ bib ]
   [AE61] K. J. Arrow and A. C. Enthoven (1961). Quasi-Concave Programming. Econometrica, 29
          (4):779--800. ISSN 00129682, 14680262.
          [ bib ]
 [ACBF02] P. Auer, N. Cesa-Bianchi, and P. Fischer (2002). Finite-time Analysis of the Multi-
          armed Bandit Problem. Machine Learning, 47(2):235--256. ISSN 1573-0565.
          [ bib | DOI ]
[ACBFS02] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire (2002). The Non-Stochastic
          Multi-Armed Bandit Problem. SIAM journal on computing, 32(1):48--77.
          [ bib ]
   [AO10] P. Auer and R. Ortner (2010). UCB Revisited: Improved Regret Bounds For The
          Stochastic Multi-Armed Bandit Problem. Periodica Mathematica Hungarica, 61(1-2):55-
          -65.
          [ bib ]
  [AGO18] P. Auer, P. Gajane, and R. Ortner (2018). Adaptively Tracking the Best Arm with an
          Unknown Number of Distribution Changes. European Workshop on Reinforcement
          Learning. https://ewrl.files.wordpress.com/2018/09/ewrl_14_2018_paper_28.pdf.
          [ bib | .pdf ]
   [AM15] O. Avner and S. Mannor (2015). Learning to Coordinate Without Communication in
          Multi-User Multi-Armed Bandit Problems. arXiv preprint arXiv:1504.08167.
          [ bib ]
   [BL18] I. Bistritz and A. Leshem (2018). Distributed MultièPlayer Bandits: a Game Of
          Thrones Approach. In Advances in Neural Information Processing Systems, pages 7222-
          -7232.
          [ bib ]
  [BMP18] R. Bonnefoi, C. Moy, and J. Palicot (2018). Improvement of the LPWAN AMI backhaul's
          latency thanks to reinforcement learning algorithms. EURASIP Journal on Wireless
          Communications and Networking, 2018(1):34. ISSN 1687-1499.
          [ bib | DOI ]
   [BP18] E. Boursier and V. Perchet (2018). SIC-MMAB: Synchronisation Involves Communication
          in Multiplayer Multi-Armed Bandits. arXiv preprint arXiv:1809.08151.
          [ bib ]
 [BCB+12] S. Bubeck, N. Cesa-Bianchi, et al. (2012). Regret Analysis of Stochastic and Non-
          Stochastic Multi-Armed Bandit Problems. Foundations and Trends in Machine Learning,
          5(1):1--122.
          [ bib ]
   [BK96] A. N. Burnetas and M. N. Katehakis (1996). Optimal Adaptive Policies for Sequential
          Allocation Problems. Advances in Applied Mathematics, 17(2):122--142.
          [ bib ]
 [CVZZ16] M. Centenaro, L. Vangelista, A. Zanella, and M. Zorzi (2016). Long-range
          communications in unlicensed bands: the rising stars in the IoT and smart city
          scenarios. IEEE Wireless Communications, 23(5):60--67. ISSN 1536-1284.
          [ bib | DOI ]
  [CMR14] O. Chapelle, E. Manavoglu, and R. Rosales (2014). Simple and Scalable Response
          Prediction For Display Advertising. Transactions on Intelligent Systems and
          Technology.
          [ bib ]
  [DMP16] S. J. Darak, C. Moy, and J. Palicot (2016). Proof-of-Concept System for
          Opportunistic Spectrum Access in Multi-user Decentralized Networks. EAI Endorsed
          Transactions on Cognitive Communications, 2.
          [ bib ]
  [GMS16] A. Garivier, P. Ménard, and G. Stoltz (2016). Explore First, Exploit Next: The True
          Shape of Regret in Bandit Problems. arXiv preprint arXiv:1602.07182.
          [ bib ]
  [Hay05] S. Haykin (2005). Cognitive Radio: Brain-Empowered Wireless Communications. IEEE
          Journal on Selected Areas in Communications, 23(2):201--220.
          [ bib ]
  [JMP12] W. Jouini, C. Moy, and J. Palicot (2012). Decision Making for Cognitive Radio
          Equipment: Analysis of the First 10 Years of Exploration. EURASIP Journal on
          Wireless Communications and Networking, 2012(1).
          [ bib ]
 [CGM+13] O. Cappé, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz (2013). Kullback-
          Leibler Upper Confidence Bounds For Optimal Sequential Allocation. Annals of
          Statistics, 41(3):1516--1541.
          [ bib ]
   [KG17] E. Kaufmann and A. Garivier (2017). Learning The Distribution With Largest Mean:
          Two Bandit Frameworks. arXiv preprint arXiv:1702.00001.
          [ bib ]
   [KL51] S. Kullback and R.A. Leibler (1951). On Information and Sufficiency. The Annals of
          Mathematical Statistics, 22(1):79--86.
          [ bib ]
   [LR85] T. L. Lai and H. Robbins (1985). Asymptotically Efficient Adaptive Allocation
          Rules. Advances in Applied Mathematics, 6(1):4--22.
          [ bib ]
   [LX10] T. L. Lai and H. Xing (2010). Sequential change-point detection when the pre-and
          post-change parameters are unknown. Sequential Analysis, 29(2):162--175.
          [ bib ]
 [Lat16b] T. Lattimore (2016). Regret Analysis of the Anytime Optimally Confident UCB
          Algorithm. arXiv preprint, arXiv:1603.08661.
          [ bib ]
   [LS19] T. Lattimore and C. Szepesvári (2019). Bandit Algorithms. http://downloads.tor-
          lattimore.com/book.pdf, draft of Friday 18th January, 2019, Revision: 1699.
          [ bib | .pdf ]
  [LKC16] A. Luedtke, E. Kaufmann, and A. Chambaz (2016). Asymptotically Optimal Algorithms
          for Multiple Play Bandits with Partial Feedback. arXiv preprint arXiv:1606.09388.
          [ bib ]
  [Lue68] D. G. Luenberger (1968). Quasi-Convex Programming. SIAM Journal on Applied
          Mathematics, 16(5):1090--1095.
          [ bib ]
  [LAL17] H. Luo, A. Agarwal, and J. Langford (2017). Efficient Contextual Bandits in Non-
          stationary Worlds. arXiv preprint arXiv:1708.01799.
          [ bib ]
   [MH16] S. Maghsudi and E. Hossain (2016). Multi-Armed Bandits with application to 5G small
          cells. IEEE Wireless Communications, 23(3):64--73. ISSN 1536-1284.
          [ bib | DOI ]
   [MM99] J. Mitola and G. Q. Maguire (1999). Cognitive Radio: making software radios more
          personal. IEEE Personal Communications, 6(4):13--18.
          [ bib ]
  [MMM17] N. Modi, P. Mary, and C. Moy (2017). QoS driven Channel Selection Algorithm for
          Cognitive Radio Network: Multi-User Multi-armed Bandit Approach. IEEE Transactions
          on Cognitive Communications and Networking, 3(1):49--66.
          [ bib ]
  [RKS17] U. Raza, P. Kulkarni, and M. Sooriyabandara (2017). Low Power Wide Area Networks:
          An Overview. IEEE Communications Surveys Tutorials, 19(2):855--873.
          [ bib | DOI ]
  [Rob52] H. Robbins (1952). Some Aspects of the Sequential Design of Experiments. Bulletin
          of the American Mathematical Society, 58(5):527--535.
          [ bib ]
  [Rob75] L. G. Roberts (1975). ALOHA packet system with and without slots and capture.
          SIGCOMM Computer Communication Review, 5(2):28--42.
          [ bib ]
  [SHK17] Adish Singla, Hamed Hassani, and Andreas Krause (2017). Learning to Use Learners'
          Advice. arXiv preprint arXiv:1702.04825.
          [ bib ]
  [Tho33] W. R. Thompson (1933). On the Likelihood that One Unknown Probability Exceeds
          Another in View of the Evidence of Two Samples. Biometrika, 25.
          [ bib ]
[TdSCC13] F. S. Truzzi, V. F. da Silva, A. H. Reali Costa, and F. Gagliardi Cozman (2013).
          AdBandit: A New Algorithm For Multi-Armed Bandits. ENIAC, 2013(1).
          [ bib ]
  [Wal45] A. Wald (1945). Some Generalizations of the Theory of Cumulative Sums of Random
          Variables. The Annals of Mathematical Statistics, 16(3):287--293.
          [ bib ]
   [ZS07] Q. Zhao and B. M. Sadler (2007). A Survey of Dynamic Spectrum Access. IEEE Signal
          Processing magazine, 24(3):79--89.
          [ bib ]
   [LZ10] K. Liu and Q. Zhao (2010). Distributed Learning in Multi-Armed Bandit with Multiple
          Players. IEEE Transaction on Signal Processing, 58(11):5667--5681.
          [ bib ]
   [AB10] J.-Y. Audibert and S. Bubeck (2010). Regret Bounds And Minimax Policies Under
          Partial Monitoring. Journal of Machine Learning Research, 11:2785--2836.
          [ bib ]
  [Bar59] G.A. Barnard (1959). Control charts and stochastic processes. Journal of the Royal
          Statistical Society. Series B (Methodological), pages 239--271.
          [ bib ]
   [PG07] F. Pérez and B. E. Granger (May 2007). IPython: a System for Interactive Scientific
          Computing. Computing in Science and Engineering, 9(3):21--29. ISSN 1521-9615. http:
          //ipython.org.
          [ bib | http ]
 [KDY+16] R. Kumar, S. J. Darak, A. Yadav, A. K. Sharma, and R. K. Tripathi (2016). Two-stage
          Decision Making Policy for Opportunistic Spectrum Access and Validation on USRP
          Testbed. Wireless Networks, pages 1--15.
          [ bib ]
 [KDY+17] R. Kumar, S. J. Darak, A. Yadav, A. K. Sharma, and R. K. Tripathi (2017). Channel
          Selection for Secondary Users in Decentralized Network of Unknown Size. IEEE
          Communications Letters, 21(10):2186--2189.
          [ bib ]
  [Hun07] J. D. Hunter (2007). Matplotlib: A 2D graphics environment. Computing In Science &
          Engineering, 9(3):90--95.
          [ bib | DOI ]
[vdWCV11] S. van der Walt, C. S. Colbert, and G. Varoquaux (March 2011). The NumPy Array: A
          Structure for Efficient Numerical Computation. Computing in Science & Engineering,
          13(2):22--30.
          [ bib | DOI ]
   [SV95] D. Siegmund and E.S. Venkatraman (1995). Using the Generalized Likelihood Ratio
          Statistic for Sequential Detection of a Change Point. The Annals of Statistics,
          pages 255--271.
          [ bib ]
  [Yaa77] M. E. Yaari (1977). A Note on Separability and Quasiconcavity. Econometrica, 45(5):
          1183--1186.
          [ bib ]
 [YRJW17] F. Yang, A. Ramdas, K. Jamieson, and M. Wainwright (2017). A framework for Multi-A
          (rmed)/B(andit) Testing with Online FDR Control. In Advances in Neural Information
          Processing Systems, pages 5957--5966.
          [ bib ]
   [CL11] O. Chapelle and L. Li (2011). An Empirical Evaluation of Thompson Sampling. In
          Advances in Neural Information Processing Systems, pages 2249--2257. Curran
          Associates, Inc.
          [ bib ]
  [Abr70] N. Abramson (1970). The ALOHA System: Another Alternative for Computer
          Communications. In Proceedings of the November 17-19, 1970, Fall Joint Computer
          Conference, AFIPS '70 (Fall), pages 281--285. ACM, New York, NY, USA.
          [ bib | DOI ]
  [ACE09] D. Agarwal, B. Chen, and P. Elango (2009). Explore Exploit Schemes For Web Content
          Optimization. In IEEE International Conference on Data Mining. IEEE.
          [ bib ]
   [AG12] S. Agrawal and N. Goyal (2012). Analysis of Thompson sampling for the Multi-Armed
          Bandit problem. In Conference On Learning Theory. PMLR.
          [ bib ]
   [AF17] R. Alami and O.-A. Maillard R. Féraud (2017). Memory Bandits: Towards the Switching
          Bandit Problem Best Resolution. In NIPS 2017 - 31st Conference on Neural
          Information Processing Systems.
          [ bib ]
   [AF15] R. Allesiardo and R. Féraud (2015). Exp3 with Drift Detection for the Switching
          Bandit Problem. In IEEE Internation Conference on Data Science and Advanced
          Analytics, pages 1--7. IEEE.
          [ bib ]
  [AMT10] A. Anandkumar, N. Michael, and A. K. Tang (2010). Opportunistic Spectrum Access
          with multiple users: Learning under competition. In IEEE INFOCOM.
          [ bib ]
  [AMS07] J.-Y. Audibert, R. Munos, and C. Szepesvári (2007). Tuning Bandit Algorithms in
          Stochastic Environments. In International Conference on Algorithmic Learning
          Theory, pages 150--165. Springer, Sendai, Japan.
          [ bib ]
   [AB09] J-Y. Audibert and S. Bubeck (2009). Minimax Policies for Adversarial and Stochastic
          Bandits. In Conference on Learning Theory, pages 217--226. PMLR.
          [ bib ]
   [AC16] P. Auer and C.-K. Chiang (2016). An Algorithm with Nearly Optimal Pseudo Regret for
          Both Stochastic and Adversarial Bandits. In Conference on Learning Theory, pages
          116--120. PMLR.
          [ bib ]
   [AM16] O. Avner and S. Mannor (2016). Multi-User Lax Communications: a Multi-Armed Bandit
          approach. In IEEE INFOCOM. IEEE.
          [ bib ]
   [AC18] A. Azari and C. Cavdar (December 2018). Self-organized Low-power IoT Networks: A
          Distributed Learning Approach. In IEEE Globecom. Abu Dhabi, UAE.
          [ bib ]
  [BGZ14] O. Besbes, Y. Gur, and A. Zeevi (2014). Stochastic Multi-Armed Bandit Problem with
          Non-Stationary Rewards. In Advances in Neural Information Processing Systems, pages
          199--207.
          [ bib ]
  [BK18a] L. Besson and E. Kaufmann (2018). Multi-Player Bandits Revisited. In Algorithmic
          Learning Theory. Mehryar Mohri and Karthik Sridharan, Lanzarote, Spain. https://
          hal.archives-ouvertes.fr/hal-01629733.
          [ bib | http ]
  [BKM18] L. Besson, E. Kaufmann, and C. Moy (2018). Aggregation of Multi-Armed Bandits
          Learning Algorithms for Opportunistic Spectrum Access. In IEEE Wireless
          Communications and Networking Conference. Barcelona, Spain. https://hal.archives-
          ouvertes.fr/hal-01705292.
          [ bib | http ]
  [BBM19] L. Besson, R. Bonnefoi, and C. Moy (April 2019). GNU Radio Implementation of MALIN:
          “Multi-Armed bandits Learning for Internet-of-things Networks”. In 2019 IEEE
          Wireless Communications and Networking Conference. Marrakech, Morocco. https://
          hal.archives-ouvertes.fr/hal-02006825, following a Demonstration presented at
          International Conference on Telecommunications (ICT) 2018.
          [ bib | http ]
  [BMP16] R. Bonnefoi, C. Moy, and J. Palicot (2016). Advanced metering infrastructure
          backhaul reliability improvement with Cognitive Radio. In SmartGridComm, pages 230-
          -236.
          [ bib | DOI ]
 [BBM+17] R. Bonnefoi, L. Besson, C. Moy, E. Kaufmann, and J. Palicot (2017). Multi-Armed
          Bandit Learning in IoT Networks: Learning helps even in non-stationary settings. In
          12th EAI Conference on Cognitive Radio Oriented Wireless Network and Communication,
          CROWNCOM Proceedings. Lisboa, Portugal.
          [ bib ]
   [BS12] S. Bubeck and A. Slivkins (2012). The Best Of Both Worlds Stochastic And
          Adversarial Bandits. In Conference on Learning Theory, pages 42--1. PMLR.
          [ bib ]
 [CZKX19] Y. Cao, W. Zheng, B. Kveton, and Y. Xie (2019). Nearly Optimal Adaptive Procedure
          for Piecewise-Stationary Bandit: a Change-Point Detection Approach. In AISTATS.
          Okinawa, Japan.
          [ bib ]
  [CMP17] R. Combes, S. Magureanu, and A. Proutiere (2017). Minimal exploration in structured
          stochastic bandits. In Advances in Neural Information Processing Systems, pages
          1761--1769.
          [ bib ]
 [CGH+96] R. Corless, G. Gonnet, D. Hare, D. Jeffrey, and D. Knuth (1996). On the Lambert W
          Function. In Advances in Computational Mathematics, pages 329--359.
          [ bib ]
   [DP16] R. Degenne and V. Perchet (2016). Anytime Optimal Algorithms In Stochastic Multi
          Armed Bandits. In International Conference on Machine Learning, pages 1587--1595.
          [ bib ]
  [GM11a] A. Garivier and E. Moulines (2011). On Upper-Confidence Bound Policies for
          Switching Bandit Problems. In International Conference on Algorithmic Learning
          Theory, pages 174--188. Springer.
          [ bib ]
   [GC11] A. Garivier and O. Cappé (2011). The KL-UCB Algorithm for Bounded Stochastic
          Bandits and Beyond. In Conference on Learning Theory, pages 359--376. PMLR.
          [ bib ]
  [GM11b] A. Garivier and E. Moulines (2011). On Upper-Confidence Bound Policies For
          Switching Bandit Problems. In Algorithmic Learning Theory, pages 174--188. PMLR.
          [ bib ]
   [GK16] A. Garivier and E. Kaufmann (2016). Optimal Best Arm Identification with Fixed
          Confidence. In PMLR, volume 49 of Conference on Learning Theory.
          [ bib ]
  [GKL16] A. Garivier, E. Kaufmann, and T. Lattimore (2016). On Explore-Then-Commit
          Strategies. In PMLR, volume 29 of Advances in Neural Information Processing Systems
          (NIPS). Barcelona, Spain.
          [ bib ]
 [GGCA11] N. Gupta, O. Granmo-Christoffer, and A. Agrawala (2011). Thompson Sampling for
          Dynamic Multi Armed Bandits. In 10th International Conference on Machine Learning
          and Applications Workshops, pages 484--489. IEEE.
          [ bib ]
 [HGB+06] C. Hartland, S. Gelly, N. Baskiotis, O. Teytaud, and M. Sebag (2006). Multi-Armed
          Bandit, Dynamic Environments and Meta-Bandits. In NIPS 2006 Workshop, Online
          Trading Between Exploration And Exploitation.
          [ bib ]
   [HT10] J. Honda and A. Takemura (2010). An Asymptotically Optimal Bandit Algorithm for
          Bounded Support Models. In Conference on Learning Theory, pages 67--79. PMLR.
          [ bib ]
 [JEMP10] W. Jouini, D. Ernst, C. Moy, and J. Palicot (2010). Upper Confidence Bound Based
          Decision Making Strategies and Dynamic Spectrum Access. In 2010 IEEE International
          Conference on Communications, pages 1--5. ISSN 1550-3607.
          [ bib | DOI ]
 [JEMP09] W. Jouini, D. Ernst, C. Moy, and J. Palicot (2009). Multi-Armed Bandit Based
          Policies for Cognitive Radio's Decision Making Issues. In International Conference
          Signals, Circuits and Systems. IEEE.
          [ bib ]
  [KNJ12] D. Kalathil, N. Nayyar, and R. Jain (2012). Decentralized Learning for Multi-Player
          Multi-Armed Bandits. In IEEE Conference on Decision and Control.
          [ bib ]
  [KCG12] E. Kaufmann, O. Cappé, and A. Garivier (2012). On Bayesian Upper Confidence Bounds
          for Bandit Problems. In AISTATS, pages 592--600.
          [ bib ]
  [KKM12] E. Kaufmann, N. Korda, and R. Munos (2012). Thompson Sampling: an Asymptotically
          Optimal Finite-Time Analysis. In Algorithmic Learning Theory, pages 199--213. PMLR.
          [ bib ]
  [KCG14] E. Kaufmann, O. Cappé, and A. Garivier (2014). On the Complexity of A/B Testing. In
          Conference on Learning Theory, pages 461--481. PMLR.
          [ bib ]
   [KS06] L. Kocsis and C. Szepesvári (2006). Discounted UCB. In 2nd PASCAL Challenges
          Workshop.
          [ bib ]
  [KHN15] J. Komiyama, J. Honda, and H. Nakagawa (2015). Optimal Regret Analysis of Thompson
          Sampling in Stochastic Multi-Armed Bandit Problem with Multiple Plays. In
          International Conference on Machine Learning, volume 37, pages 1152--1161. PMLR.
          [ bib ]
  [TRY17] K. Tomer, L. Roi, and M. Yishay (2017). Bandits with Movement Costs and Adaptive
          Pricing. In Conference on Learning Theory, volume 65, pages 1242--1268. PMLR.
          [ bib ]
  [KPV17] J. Kwon, V. Perchet, and C. Vernade (2017). Sparse Stochastic Bandits. In
          Conference on Learning Theory, pages 1269--1270.
          [ bib ]
  [LVC16] P. Lagrée, C. Vernade, and O. Cappé (2016). Multiple-Play Bandits in the Position-
          Based Model. In Advances in Neural Information Processing Systems, pages 1597--
          1605.
          [ bib ]
 [Lat16c] T. Lattimore (2016). Regret Analysis Of The Finite Horizon Gittins Index Strategy
          For Multi Armed Bandits. In Conference on Learning Theory, pages 1214--1245. PMLR.
          [ bib ]
   [LM09] A. Lazaric and R. Munos (2009). Hybrid Stochastic-Adversarial On-Line Learning. In
          Conference on Learning Theory.
          [ bib ]
 [LCLS10] L. Li, W. Chu, J. Langford, and R. E. Schapire (2010). A Contextual-Bandit Approach
          to Personalized News Article Recommendation. In International Conference on World
          Wide Web, pages 661--670. ACM.
          [ bib ]
 [LPSY18] D. Liau, E. Price, Z. Song, and G. Yang (2018). Stochastic Multi-Armed Bandits in
          Constant Space. In International Conference on Artificial Intelligence and
          Statistics.
          [ bib ]
   [LZ08] K. Liu and Q. Zhao (2008). A Restless Bandit Formulation of Opportunistic Access:
          Indexablity and Index Policy. In IEEE Annual Communications Society Conference on
          Sensor, Mesh and Ad-Hoc Communications and Networks Workshops.
          [ bib ]
  [LLS18] F. Liu, J. Lee, and N. Shroff (2018). A Change-Detection based Framework for
          Piecewise-stationary Multi-Armed Bandit Problem. In The Thirty-Second AAAI
          Conference on Artificial Intelligence (AAAI 2018).
          [ bib ]
 [LRC+16] J. Louëdec, L. Rossi, M. Chevalier, A. Garivier, and J. Mothe (2016). Algorithme de
          bandit et obsolescence : un modèle pour la recommandation. In 18ème Conférence
          francophone sur l'Apprentissage Automatique, 2016 (Marseille, France).
          [ bib ]
   [MM11] O.-A. Maillard and R. Munos (2011). Adaptive Bandits: Towards the best history-
          dependent strategy. In AISTATS, pages 570--578.
          [ bib ]
  [Mai19] O.-A. Maillard (2019). Sequential change-point detection: Laplace concentration of
          scan statistics and non-asymptotic delay bounds. In Algorithmic Learning Theory.
          [ bib ]
   [MS13] J. Mellor and J. Shapiro (2013). Thompson Sampling in Switching Environments with
          Bayesian Online Change Detection. In Artificial Intelligence and Statistics, pages
          442--450.
          [ bib ]
   [MG17] P. Ménard and A. Garivier (2017). A Minimax and Asymptotically Optimal Algorithm
          for Stochastic Bandits. In Algorithmic Learning Theory, volume 76, pages 223--237.
          PMLR.
          [ bib ]
 [MTC+16] A. Maskooki, V. Toldov, L. Clavier, V. Loscrí, and N. Mitton (February 2016).
          Competition: Channel Exploration/Exploitation Based on a Thompson Sampling Approach
          in a Radio Cognitive Environment. In EWSN-International Conference on Embedded
          Wireless Systems and Networks (dependability competition). Graz, Austria.
          [ bib ]
   [MM17] J. Mourtada and O.-A. Maillard (2017). Efficient Tracking of a Growing Number of
          Experts. In Algorithmic Learning Theory, volume 76 of Proceedings of Algorithmic
          Learning Theory, pages 1--23. Tokyo, Japan.
          [ bib ]
  [RSS16] J. Rosenski, O. Shamir, and L. Szlak (2016). Multi-Player Bandits -- A Musical
          Chairs Approach. In International Conference on Machine Learning, pages 155--163.
          PMLR.
          [ bib ]
  [SLM12] Amir Sani, Alessandro Lazaric, and Rémi Munos (2012). Risk-Aversion In Multi-Armed
          Bandits. In Advances in Neural Information Processing Systems, pages 3275--3283.
          [ bib ]
   [SL17] Y. Seldin and G. Lugosi (2017). An Improved Parametrization and Analysis of the
          EXP3++ Algorithm for Stochastic and Adversarial Bandits. In Conference on Learning
          Theory, volume 65, pages 1--17. PMLR.
          [ bib ]
   [TL11] C. Tekin and M. Liu (2011). Performance and Convergence of Multi-User Online
          Learning. In International Conference on Game Theory for Networks, pages 321--336.
          Springer Berlin Heidelberg.
          [ bib ]
   [TL12] C. Tekin and M. Liu (2012). Online Learning in Decentralized Multi-User Spectrum
          Access with Synchronized Explorations. In IEEE Military Communications Conference.
          [ bib ]
 [TCLM16] V. Toldov, L. Clavier, V. Loscrí, and N. Mitton (September 2016). A Thompson
          Sampling Approach To Channel Exploration Exploitation Problem In Multihop Cognitive
          Radio Networks. In PIMRC, pages 1--6. Valencia, Spain.
          [ bib | DOI ]
  [WS18b] L. Wei and V. Srivastava (2018). On Distributed Multi-player Multiarmed Bandit
          Problems in Abruptly Changing Environment. In 2018 IEEE Conference on Decision and
          Control (CDC), pages 5783--5788. IEEE.
          [ bib ]
  [YFE12] X. Yang, A. Fapojuwo, and E. Egbogah (September 2012). Performance Analysis and
          Parameter Optimization of Random Access Backoff Algorithm in LTE. In 2012 IEEE
          Vehicular Technology Conference (VTC Fall), pages 1--5. ISSN 1090-3038.
          [ bib | DOI ]
   [YM09] J. Y. Yu and S. Mannor (2009). Piecewise-Stationary Bandit Problems with Side
          Observations. In Proceedings of the International Conference on Machine Learning
          (ICML), pages 1177--1184. ACM.
          [ bib ]
  [ABM10] J-Y. Audibert, S. Bubeck, and R. Munos (2010). Best Arm Identification in Multi-
          Armed Bandits. In Conference on Learning Theory, pages 13--p. PMLR.
          [ bib ]
[ACBFS95] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire (1995). Gambling in a Rigged
          Casino: The Adversarial Multi-Armed Bandit Problem. In Annual Symposium on
          Foundations of Computer Science, pages 322--331. IEEE.
          [ bib ]
   [K+16] T. Kluyver et al. (2016). Jupyter Notebooks -- a publishing format for reproducible
          computational workflows. In F. Loizides and B. Schmidt, editors, Positioning and
          Power in Academic Publishing: Players, Agents and Agendas, pages 87--90. IOS Press.
          [ bib ]
 [KAF+18] R. Kerkouche, R. Alami, R. Féraud, N. Varsier, and P. Maillé (2018). Node-based
          optimization of LoRa transmissions with Multi-Armed Bandit algorithms. In
          International Conference on Telecommunications. J. Palicot and R. Pyndiah, Saint-
          Malo, France.
          [ bib ]
   [D+16] S. J. Darak et al. (2016). Spectrum Utilization and Reconfiguration Cost Comparison
          of Various Decision Making Policies for Opportunistic Spectrum Access Using Real
          Radio Signals. In CROWNCOM 2016. Grenoble, France.
          [ bib ]
  [Chi18] F. Chiusano (2018). Breakpoint Prediction for the Abruptly-Switching Non-Stationary
          Multi-Armed Bandit Problem. Master's thesis, Politecnico Di Milano, AI & R Lab,
          Laboratorio di Intelligenza Artificiale e Robotica del Politecnico di Milano.
          [ bib ]
  [Wei17] E. W. Weisstein (2017). Exponential Integral. http://mathworld.wolfram.com/
          ExponentialIntegral.html. From MathWorld -- A Wolfram Web Resource.
          [ bib ]
  [Col17] Collective (2017). Exponential Integral. https://en.wikipedia.org/wiki/
          Exponential_integral. From Wikipedia, The Free Encyclopedia.
          [ bib ]
   [GNUb] GRC Documentation. https://wiki.gnuradio.org/index.php/GNURadioCompanion. Accessed:
          2018-09-25.
          [ bib ]
   [GNUa] GNU Radio Documentation. https://www.gnuradio.org/about/. Accessed: 2018-09-25.
          [ bib ]
    [Oct] OctoClock Clock Distribution Module with GPSDO - Ettus Research. http://
          www.ettus.com/product/details/OctoClock-G. Accessed: 2018-09-25.
          [ bib ]
  [Bes19] L. Besson (2016--2019). SMPyBandits: an Open-Source Research Framework for Single
          and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python. Code at https://
          GitHub.com/SMPyBandits/SMPyBandits/, documentation at https://
          SMPyBandits.GitHub.io/.
          [ bib ]
 [Lat16a] T. Lattimore (2016). Library for Multi-Armed Bandit Algorithms. Online at: https://
          github.com/tor/libbandit. https://github.com/tor/libbandit.
          [ bib | http ]
    [USR] USRP Hardware Driver and USRP Manual. http://files.ettus.com/manual/
          page_usrp2.html. Accessed: 2018-09-25.
          [ bib ]
  [Raj17] V. Raj (2017). A Julia Package for providing Multi Armed Bandit Experiments. Online
          at: https://github.com/v-i-s-h/MAB.jl. https://github.com/v-i-s-h/MAB.jl.
          [ bib | http ]
   [C+18] A. Collette et al. (2018). h5py: HDF5 for Python. Online at: http://www.h5py.org.
          http://www.h5py.org.
          [ bib | http ]
  [Var17] G. Varoquaux (March 2017). Joblib: running Python functions as pipeline jobs.
          Online at: joblib.readthedocs.io. joblib.readthedocs.io.
          [ bib | www: ]
   [I+17] Anaconda Inc. et al. (2017). Numba, NumPy aware dynamic Python compiler using LLVM.
          Online at: numba.pydata.org. numba.pydata.org.
          [ bib | www: ]
  [CGK12] O. Cappé, A. Garivier, and E. Kaufmann (2012). pymaBandits. Online at: http://
          mloss.org/software/view/415. http://mloss.org/software/view/415, online at: http://
          mloss.org/software/view/415.
          [ bib | http ]
  [Fou17] Python Software Foundation (October 2017). Python Language Reference, version 3.6.
          Online at: https://www.python.org. https://www.python.org.
          [ bib | http ]
 [JOP+01] E. Jones, T. E. Oliphant, P. Peterson, et al. (2001). SciPy: Open source scientific
          tools for Python. Online at: https://www.scipy.org. https://www.scipy.org.
          [ bib | http ]
   [W+17] M. Waskom et al. (September 2017). Seaborn: statistical data visualization. Online
          at: seaborn.pydata.org. seaborn.pydata.org.
          [ bib | DOI | www: ]
   [B+18] G. Brandl et al. (2018). Sphinx: Python documentation generator. Online at: http://
          sphinx-doc.org. http://sphinx-doc.org.
          [ bib | http ]
  [BP+16] I. Bicking, PyPA, et al. (November 2016). Virtualenv: a tool to create isolated
          Python environments. Online at: virtualenv.pypa.io/en/stable. virtualenv.pypa.io/
          en/stable.
          [ bib | www: ]
  [Bod17] Q. Bodinier (2017). Coexistence of Communication Systems Based on Enhanced Multi-
          Carrier Waveforms with Legacy OFDM Networks. Ph.D. thesis, CentraleSupélec. https:/
          /www.theses.fr/2017REN1S091.
          [ bib | http ]
  [Kau14] E. Kaufmann (2014). Analysis of Bayesian and Frequentist Strategies for Sequential
          Resource Allocation. Ph.D. thesis, Telecom ParisTech. https://www.theses.fr/
          2014ENST0056.
          [ bib | http ]
  [Mod17] N. Modi (2017). Machine Learning and Statistical Decision Making for Green Radio.
          Ph.D. thesis, CentraleSupélec, IETR, Rennes. https://www.theses.fr/2017SUPL0002.
          [ bib | http ]
  [Tol17] V. Toldov (2017). Adaptive MAC Layer for Interference Limited WSN. Ph.D. thesis,
          Université Lille 1 Sciences et technologies. https://www.theses.fr/2017LIL10002.
          [ bib | http ]
  [BBM18] L. Besson, R. Bonnefoi, and C. Moy (June 2018). Multi-Arm Bandit Algorithms for
          Internet of Things Networks: A TestBed Implementation and Demonstration that
          Learning Helps. http://ict-2018.org/demos,https://youtu.be/HospLNQhcMk,
          Demonstration presented at International Conference on Telecommunications.
          [ bib | http ]
  [BK18b] L. Besson and E. Kaufmann (February 2018). What Doubling Trick Can and Can't Do for
          Multi-Armed Bandits. https://hal.archives-ouvertes.fr/hal-01736357, preprint,
          https://hal.archives-ouvertes.fr/hal-01736357.
          [ bib | http | http ]
   [BK19] L. Besson and E. Kaufmann (February 2019). Combining the Generalized Likelihood
          Ratio Test and kl-UCB for Non-Stationary Bandits. https://SMPyBandits.GitHub.io/
          NonStationary.html, preprint, https://hal.archives-ouvertes.fr/hal-02006471.
          [ bib | .html ]
 [GHMS18] A. Garivier, H. Hadiji, P. Ménard, and G. Stoltz (2018). KL-UCB-switch: optimal
          regret bounds for stochastic bandits from both a distribution-dependent and a
          distribution-free viewpoints. HAL preprint hal-01785705. https://hal.archives-
          ouvertes.fr/hal-01785705.
          [ bib | http ]
   [KK18] E. Kaufmann and W.M. Koolen (2018). Mixture Martingales Revisited with Applications
          to Sequential Tests and Confidence Intervals. https://arXiv.org/abs/1811.11419,
          arXiv preprint arXiv:1811.11419.
          [ bib | http ]
   [MM19] S. Mukherje and O.-A. Maillard (2019). Improved Changepoint Detection for Piecewise
          i.i.d Bandits. Working paper or preprint.
          [ bib ]
   [RK17] V. Raj and S. Kalyani (2017). Taming Non-Stationary Bandits: a Bayesian Approach.
          https://arxiv.org/abs/1707.09727, arXiv preprint arXiv:1707.09727.
          [ bib | http ]
  [Bes18] L. Besson (2018). SMPyBandits: an Experimental Framework for Single and Multi-
          Players Multi-Arms Bandits Algorithms in Python. https://hal.archives-ouvertes.fr/
          hal-01840022, preprint, submitted to JMLR MLOSS, https://hal.archives-ouvertes.fr/
          hal-01840022.
          [ bib | http | http ]
  [WS18a] L. Wei and V. Srivastava (2018). On Abruptly-Changing and Slowly-Varying Multiarmed
          Bandit Problems. https://arxiv.org/abs/1802.08380, arXiv preprint arXiv:1802.08380.
          [ bib | http ]
  [BN+93] M. Basseville, I. Nikiforov, et al. (1993). Detection of Abrupt Changes: Theory And
          Application, volume 104. Prentice Hall Englewood Cliffs.
          [ bib ]
  [Bón11]M. Bóna (2011). A Walk Through Combinatorics: an Introduction to Enumeration and
          Graph Theory. World Scientific.
          [ bib ]
  [BLM13] S. Boucheron, G. Lugosi, and P. Massart (2013). Concentration Inequalities: A
          Nonasymptotic Theory of Independence. Oxford university press.
          [ bib ]
   [BV04] S. Boyd and L. Vandenberghe (2004). Convex Optimization. Cambridge Univ. Press.
          [ bib ]
  [CBL06] N. Cesa-Bianchi and G. Lugosi (2006). Prediction, Learning, and Games. Cambridge
          University Press.
          [ bib ]
  [Nor98] J. R. Norris (1998). Markov Chains, volume 2 of Cambridge Series in Statistical and
          Probabilistic Mathematics. Cambridge University Press, Cambridge.
          [ bib ]
  [Sie13] D. Siegmund (2013). Sequential analysis: tests and confidence intervals. Springer
          Science & Business Media.
          [ bib ]
  [TNB15] A. Tartakovsky, I. Nikiforov, and M. Basseville (2015). Sequential Analysis.
          Hypothesis Testing and Changepoint Detection. CRC Press.
          [ bib ]
