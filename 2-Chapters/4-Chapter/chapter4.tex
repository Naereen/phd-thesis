%!TEX root = ../PhD_thesis__Lilian_Besson

% ----------------------------------------------------------------------
\chapter{Improving Spectrum Usage of IoT Networks with Selfish MAB Learning}
\label{chapter:4}

\graphicspath{{2-Chapters/4-Chapter/Images/}}


\abstractStartChapter{}%
%
In this chapter, we propose two models of Internet of Things (IoT) networks, composed of many independent IoT end-devices,
that can use low-cost RL (Reinforcement Learning) algorithms to learn to improve their spectrum access.
%
Decentralized RL for IoT lets the devices use acknowledgements sent by their Base Station as a reward, instead of sensing feedback like for OSA.
We consider many independent ``dynamic'' devices, communicating with a small probability at every instant.
Simulations show that dynamic devices can improve their spectrum efficiency,
by using MAB algorithms like \UCB.
% in the case of a non-uniform repartition of the static devices in the channels
We also developed a proof-of-concept using USRP platforms, for a real-world validation of this approach.
% Numerical simulations justify the interest of the approach,
%  of the advantage of using MAB algorithms for the first model.
%
% On a simple example, we present in Section~\ref{sec:4:gnuradio} a demonstration that implements and validates the proposed approach, using real wireless radio hardware.
The first model
% without retransmission of packets,
is interesting for its simplicity,
and because considering no retransmission can improve the battery life of IoT devices, at the cost of a lower Quality of Service (QoS).

However, in case of failed transmission of a message, a dynamic device can also retransmit it up-to a fixed number of retransmission.
We compare different heuristics, based on \UCB, and numerical simulations confirm that the non-naive heuristics significantly improve the network efficiency.
% Interestingly, the simplest heuristic is found to be the most efficient one, as its simplicity implies a faster learning and convergence time.
%
The second model is more interesting if the main target is an improvement of the QoS, rather than a longer battery life.

\minitocStartChapter{}

% ----------------------------------------------------------------------------
% \section{Motivations for Selfish MAB Learning for IoT Networks}
\section{Introduction and motivations for MAB learning for IoT Networks}
\label{sec:4:motivations}
% ----------------------------------------------------------------------

We already explained in Chapter~\ref{chapter:1} that
unlicensed bands are more and more used and considered for mobile and LAN communication standards (WiFi, LTE-U), and for Internet of Things (IoT) standards for short-range (ZigBee, Z-Wave, Bluetooth) and long-range (LoRaWAN, SIGFOX, Ingenu, Weightless) communications \cite{Centenaro16}.
This heavy use of unlicensed bands, in particular with the expected exponential growth of the number of IoT devices, will cause performance drop, due to radio collisions that could even compromise IoT promises.

Efficient Medium Access (MAC) policies allow devices to avoid interfering traffic and can significantly reduce the spectrum contention problem in unlicensed bands.
As end-devices battery life is a key constraint of IoT networks,
and as IoT networks are decentralized (\ie, the devices initiate transmissions),
this leads to IoT protocols using as low signaling overhead as possible and simple ALOHA-based mechanisms.
%
In this chapter, we analyze the performance of Multi-Armed Bandits (MAB) algorithms, that could be used in combination with a time-frequency slotted ALOHA-based protocol.
We highlight that even without changing anything on the level of IoT standards, our proposal is just an add-on capability that can be used on a unit-per-unit basis.
We consider the Upper-Confidence Bound (\UCB) \cite{Auer02}, and the Thompson-Sampling (TS) algorithms \cite{Thompson33,AgrawalGoyal11,
Kaufmann12Thompson}, for the first model. For the demonstration as well as for the second model, without loss of generality, we preferred to focus on heuristics based on the simplest algorithm (\ie, \UCB), to give a clear presentation of the different ideas explored to solve the problem of learning in order to retransmit efficiently.

As detailed in Chapter~\ref{chapter:1},
MAB learning has already been proposed in Cognitive Radio (CR) \cite{Mitola99,Haykin05}, and in particular, for sensing-based Dynamic Spectrum Access (DSA) in licensed bands \cite{Jouini10}.
For example,
proof-of-concepts like \cite{kumar2016two} have proven the capability of such approaches on real radio signals for OSA,
and \cite{Maghsudi16} shows how MAB learning can be applied for small cell management in licensed 5G networks.
Some analysis on real radio measurements made for HF ionospheric channels have also proven that solutions based on MAB learning is appropriate and solves efficiently this kind of decision-making problems on real-world wireless signals \cite{Melian15}.
Recent works show that stationary MAB algorithms work well to solve reinforcement learning models that represent accurately real-world radio problems.
Recently, TS and \UCB{} algorithms have been used for improving the spectrum access in (unlicensed) WiFi networks, for instance by \cite{Toldov16} or \cite{Wilhelmi19collaborative,Wilhelmi19potential}.
% However, even with only one dynamic user using the learning algorithm, the background traffic or the traffic of the other devices is never really stationary or \iid{}.

We present in Section~\ref{sec:4:firstModel} how the MAB algorithms can be used in a unlicensed but frequency- and time-slotted IoT network.
Several devices are using bandit algorithms, and the assumptions made by the stochastic bandit algorithms are not satisfied: as several agents learn simultaneously and their activation processes are random, their behavior is not stationary.
As far as we know, we provide the first practical study to confirm robustness of the use of stochastic bandit algorithms for decision making in IoT networks with a large number of intelligent devices in the network, which makes the environment ``highly not stationary''.
This specific context makes it very hard to give mathematical proofs of  convergence and efficiency for bandit algorithms (that is why we relax the hypothesis and only consider up-to $M \leq K$ players in Chapter~\ref{chapter:5}).
We then validate the model with a hardware implementation on real radio signals, detailed in Section~\ref{sec:4:gnuradio}.
%
We conclude this chapter by presenting in Section~\ref{sec:4:retransmissions} an extension of this model to take into account another aspect of the ALOHA protocol, that is the possibility for dynamic devices to retransmit their packet if the \emph{Ack} was not received.


\textbf{Publications.}
%
This chapter is mainly based on our articles \cite{Bonnefoi17,Besson2018ICT,Besson2019WCNC,Bonnefoi2019WCNC,MoyBesson2019}.


% ----------------------------------------------------------------------------
\section[Selfish learning for many dynamic devices in an IoT network]{Selfish learning for many dynamic devices with low activation probabilities in an IoT network}
\label{sec:4:firstModel}
% ----------------------------------------------------------------------

% - ``Multi-Armed Bandit Learning in IoT Networks and non-stationary settings'', see https://hal.inria.fr/hal-01575419

\input{2-Chapters/4-Chapter/CrownCom_17.git/IoT_slotted.tex}


% ----------------------------------------------------------------------------
\section{Test-bed implementation of our model for real-world validation}
\label{sec:4:gnuradio}
% ----------------------------------------------------------------------

% - ``MALIN: Multi-Arm bandit Learning for Iot Networks with GRC: A TestBed Implementation and Demonstration that Learning Helps'', demo at ICT, and the companion paper ``GNU Radio Implementation of MALIN: "Multi-Armed bandits Learning for Internet-of-things Network"'', see https://hal.inria.fr/hal-02006825

\input{2-Chapters/4-Chapter/IEEE_WCNC_2019__DemoICT.git/main.tex}



% ----------------------------------------------------------------------------
\section{Extending the model to account for retransmissions}
\label{sec:4:retransmissions}
% ----------------------------------------------------------------------

% - ``Upper-Confidence Bound for Channel Selection in LPWA Networks with Retransmissions'', see \texttt{https://perso.crans.org/besson/articles/BMBM\_\_IEEE\_WCNC\_2019.pdf}

\input{2-Chapters/4-Chapter/IEEE_WCNC__2019__Paper__BMBM.git/IEEE_WCNC__2019__Paper__BMBM.tex}


\newpage  % WARNING ?
% ----------------------------------------------------------------------------
\section{Conclusion}
\label{sec:4:conclusion}
% ----------------------------------------------------------------------

% % We give in this section conclusions about the two models presented above, one for long-life IoT devices (without retransmission) and for improved QoS devices (\ie, with retransmissions), and about our demonstration, as well as directions of future works, some of which are currently being studied by researchers of our team.

% % \subsection*{Conclusions}

% % ----------------------------------------------------------------------
% % \paragraph{Summary of the first model.}
% \label{sub:41:conclusion}

% In Section~\ref{sec:4:firstModel}, we proposed an evaluation of the performance of MAB learning algorithms in IoT networks,
% with a focus on the convergence of algorithms, in terms of successful transmission rates, when the proportion of intelligent dynamic devices changes.
% Concretely, increasing this probability allows to insert more devices in the same network, while maintaining a good Quality of Service.
% Similarly, if the number of devices remain constant, increasing the successful transmission rate directly extends the IoT devices battery life, as they suffer less from failed transmissions.
% We show that \UCB{} and TS have near-optimal performance, even when their underlying \iid{} assumption (see Chapter~\ref{chapter:2}) is violated by the presence of many ``intelligent'' end-devices which follow a random activation process.
% %
% This is both surprising and encouraging, it shows that applying bandit algorithms tailored for a stochastic model is still useful in broader settings.
% The fully \emph{decentralized} application of classic stochastic MAB algorithms are almost as efficient as the best possible centralized policy in this setting, after a short learning period, even though the dynamic devices \emph{cannot} communicate with each other, and \emph{do not} know the system parameters.


% % ----------------------------------------------------------------------
% % \paragraph{Conclusions taken from the demonstration.}
% \label{sub:42:conclusionFromDemonstration}

% We presented in Section~\ref{sec:4:gnuradio} a demonstration, showed in $2018$ at the ICT conference \cite{Besson2018ICT}, and further detailed in the companion paper \cite{Besson2019WCNC}.
% We gave all the necessary details on both the PHY and the MAC layer, as well as details on the User Interface developed for the demo.
% Results obtained in practice were discussed, to highlight the interest of using learning algorithms for radio online optimization problem, and especially multi-armed bandit learning algorithms.
% %
% By using such low-cost algorithms, we demonstrated empirically that a dynamically re-configurable device can learn on its own to favor a certain channel, if the environment traffic is not uniform between the $K$ different channels, by using the acknowledgement (\Ack) feedback sent from the base station.


% % ----------------------------------------------------------------------
% % \paragraph{Conclusion about this second model.}
% \label{sub:43:conclusion}

% In Section~\ref{sec:4:retransmissions}, we presented an extension of our model of LPWA networks based on an ALOHA protocol, slotted both in time and frequency.
% % , in which dynamic IoT devices can again use machine learning algorithms, to improve their Packet Loss Ratio (PLR) when accessing the network.
% If the priority is the Quality of Service, for instance with renewable energy capabilities, this second model is more appropriate.
% The main novelty of this model is to address the packet retransmissions upon radio collision, by using a Multi-Armed Bandit framework.
% We presented and evaluated several heuristics that try to learn how to transmit and retransmit in a smarter way, by using the \UCB{} algorithm for channel selection for first transmission, and different proposals based on \UCB{} for the retransmissions upon collisions.
% %
% We showed that incorporating learning for the transmission is needed to achieve optimal performance, with significant gain in terms of successful transmission rate in networks with a large number of devices (up-to $30\%$ in the example network).
% Our simulations show that each of our proposed heuristic outperforms a naive random access scheme.
% Surprisingly, the main take-away message is that a simple \UCB{} learning approach, that retransmit in the same channel, turns out to perform as well as more complicated heuristics.


% % ----------------------------------------------------------------------
% \subsection*{Future works}
% \label{sub:4:futureWorks}

% % Future works related to this chapter include the following directions.


% % \paragraph{Possible extensions of the first model.}

% The first model presented in Section~\ref{sec:4:firstModel} could easily be generalized with two probabilities $p_S$ and $p_D$, if static and dynamic devices have different transmission pattern, and less easily with one probability per device. Also, other emission pattern could be considered, instead of a Bernoulli process for each user.
% In this whole Chapter~\ref{chapter:4}, we prefer to consider that all devices have the same activation probability, to keep the notation as simple as possible.
% %
% Moreover, for sake of simplicity we supposed that all devices use the same standard.
% Future works could consider more realistic interference scenarios and IoT networks, with, \eg, non-slotted time, more than one base station etc.

% Another extension could be to not have a Bernoulli process (or any random process), but a fixed rate of transmission, \eg, one transmission a day.
% So additionally to deciding the channel for communication (\ie, \emph{where} to communicate), each device has to also decide \emph{when} to communicate.
% % This is another direction of research, that we will investigate in the future.
% However, this clearly leads to a much larger action space, as there are many time slots in one day (for example), and thus we believe that as soon as the action space becomes too large in this extension, the simple MAB-based learning approach could be no longer appropriate.
% It is well-known in the MAB literature that the larger the action space, the slower is the convergence speed of any stationary MAB algorithms.
% It could be interesting to study the possible application of \emph{contextual} MAB \cite{Li10,Luo18} or structured MAB \cite{Combes17} models and algorithms for this extension.

% % We will investigate this behavior in order to understand it better theoretically.
% % We will also experiment more with adversarial algorithms, to confirm that they work less efficiently than stochastic bandit algorithms in our non-stochastic setting.

% % \paragraph{Extensions of the demonstration.}

% Possible future extensions of our demonstration include the following points.
% We could consider more dynamic devices (\eg, $100$) but it would either cost more in terms of equipment, or in terms of software engineering to simulation more devices with the same card.
% We could also implement a real-world IoT communication protocol (like the LoRaWAN standard), which we prefer not to do as it would cost a significant effort of development.
% Finally, we could also study the interference in case of other gateways located nearby, and this could be done without needing a lot of new hardware (using one extra USRP card to simulate another gateway).
% %
% % Pub pour notre autre article
% % We are also interested in studying the possible gain of using a learning step when the transmission model follows ALOHA-like retransmissions, and this is presented in the next Section~\ref{sec:4:retransmissions}.


% % \paragraph{Possible extensions for the second model.}

% Finally, the utility and impact of the proposed approaches for LPWA networks motivates us to address several subjects as future works. Among them, the non-stationarity of the channel occupancy caused by the learning policy employed by the IoT devices.
% %
% For that end, modifications of MAB algorithms have been proposed, such as Sliding-Window-\UCB{} or Discounted-\UCB{} \cite{Garivier11UCBDiscount}
% or more recently M-\UCB{} \cite{CaoZhenKvetonXie18},
% or more recently GLR-\UCB{} \cite{Besson2019GLRT} which is presented in Chapter~\ref{chapter:6},
% that nevertheless have not been explored for the targeted problem.
% Chapter~\ref{chapter:6} is focusing on this direction, but we did not have enough time to explore the possible applications of MAB policies designed for non-stationary problems to the model with retransmissions presented in this Chapter.

% In order to validate our results in a realistic experimental setting and not only with simulations, future works include a hardware implementation of the analyzed models to complete our demonstration \cite{Besson2019WCNC}.
% Note that Julio César Mango-Vasquez is currently working on this direction, for the EPHYL project, in collaboration with Carlos Faouzi Bader at IETR and CentraleSupélec campus of Rennes.
% % and Christophe Moy at IETR and University Rennes 1.
% %
% A hardware demonstrator could be also benefit to study other settings by removing some hypotheses, for instance by studying a similar model in non-slotted time.


% \subsection*{Summary of this chapter}

To sum-up, we focused in this chapter on models of IoT networks, and we proposed to use classical stationary multi-armed bandit learning algorithms implemented in a selfish and decentralized manner by each of the dynamic devices of the IoT network.
We presented two models of wireless IoT network without sensing, inspired by the ALOHA protocol, and with or without retransmission of uplink packages in case of collisions.
In both cases, we try to model the existing standards, like the LoRa standard, and we demonstrated the efficiency of the proposed MAB-based approach in both numerical simulations and empirical measurements on real wireless radio signals.

A satisfying message is that this learning-based approach seems to be very efficient, as it allows the IoT devices to automatically and independently increase their successful transmission rate.
It is also quite surprising that stochastic MAB algorithms can be of any use in such non-stationary applications.
Sadly, analyzing our model with thousands of independent devices communicating and learning in their own (random) time scales turned out to be of extreme difficulty.
%
We can also highlight that the two models we studied are complementary:
the first model (without retransmission of packets), is interesting for its simplicity, and focused on improving the battery life of IoT devices, at the cost of a lower Quality of Service (QoS),
%
while the second model is more interesting if the main target is an improvement of the QoS, rather than a longer battery life.


\textbf{Multi-Players MAB.}
%
On the first hand, we are actually able to analyze a simpler model, if we assume to have at most $M \leq K$ devices with a transmission probability of $p=1$.
Instead of the experiment-driven direction pursued in this chapter, another possibility is to consider a \emph{multi-players MAB} model to describe our problem.
%
The main difference between the two models is the fact that in this chapter, devices do not transmit their messages at every time step, but following a random activation process (with a fixed transmission probability $p < 1$).
If static and dynamic devices that have to transmit at a fixed time are denoted \emph{active devices},
then their random activation patter makes the number of active devices an (unpredictable) random variable.
Analyzing multi-players MAB models under this hypothesis is much harder, and is left as a future work.
%
We study this first direction in the next Chapter~\ref{chapter:5}.

% In that case, the static and dynamic devices effect is decoupled, and arms only model the availability of the channels in the absence of dynamic devices: they are \iid{} with mean $\mu_i = 1 - p S_i$.
% Moreover, dynamic devices are usually assumed to be able to \emph{sense} a channel before sending \cite{Zhao10}, and so communicate only if no static device is detected on the channel.
% The smart devices try to learn the arms with highest means, while coordinating to choose different arms, \ie, avoid collisions in their choice, in a decentralized manner.
% However, in this model it is assumed that the multiple agents can know that they experienced a collision with another agent, which is non-realistic for our problem at stake, as our model of smart device cannot do sensing nor differentiate collisions between smart and non-smart devices.


\textbf{Non-stationary MAB.}
%
On the other hand, while it is hard to analyze the models of this chapter due to their non-stationary behaviors, we are also able to analyze a simpler model, if we focus on a single player accessing a network which is assumed to be \emph{piece-wise stationary}
(MAB problems which are stationary on ``long enough'' intervals, of unknown locations and lengths).
%
We also study this second direction in Chapter~\ref{chapter:6}.


\newpage
% ----------------------------------------------------------------------------
\section{Appendix}
\label{sec:4:appendix}

\subsection{Proof of Proposition~\ref{prop:41:Lagrangian}}
\label{sec:4:proofLagrangian}
% ----------------------------------------------------------------------------

% We include here a missing proof from Section~\ref{sec:4:firstModel}.

\input{2-Chapters/4-Chapter/CrownCom_17.git/IoT_slotted_appendix.tex}


\newpage
\subsection{Illustration of the GNU Radio Companion Flowcharts}
\label{sec:4:IllustrationFlowcharts}
% ----------------------------------------------------------------------------

\input{2-Chapters/4-Chapter/IEEE_WCNC_2019__DemoICT.git/main_appendix.tex}
