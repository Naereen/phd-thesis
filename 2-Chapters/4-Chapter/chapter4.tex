%!TEX root = ../PhD_thesis__Lilian_Besson

% ----------------------------------------------------------------------
\chapter{Improving Spectrum Usage of IoT Networks with Selfish MAB Learning}
\label{chapter:4}
\minitoc
% ----------------------------------------------------------------------

\paragraph{Abstract}

In this Chapter~\ref{chapter:4}, we present two models of Internet of Things networks, composed of many independent devices that are able to run MAB algorithm to learn and improve their access to the network.
The two models are presented mathematically, and numerical simulations justify the interest of the proposed algorithms.
We also present a proof-of-concept real-world validation of the advantage of using Multi-Armed Bandit algorithms for the first model, by showing and explaining a demonstration implemented on USRP platforms \cite{USRPDocumentation}.

More precisely, we start by motivating this idea of independent ``selfish'' learning for IoT devices in Section~\ref{sec:4:motivations}.
We then present in Section~\ref{sec:4:firstModel} a model where independent devices use an IoT network composed of different channels, occupied by static devices.
Devices do not use any sensing, but use acknowledgements sent by the Base Station to know if their uplink messages were successfully received.
We consider the case when many independent ``dynamic'' devices all have a small probability of communicating at every discrete time. If they use simple MAB algorithms in a decentralized and independent fashion (what we call ``selfish'' learning),
we show in simulations that in the case of a non-uniform repartition of the static devices in the channels, the dynamic devices can drastically improve the network efficiency.
%
On a simple example, we present in Section~\ref{sec:4:gnuradio} a demonstration that implements and validates the proposed approach, using real wireless radio hardware.

We then present in Section~\ref{sec:4:retransmissions} a second model extending our first model, when devices can retransmit their messages for a fixed number of maximum retransmission (like in the ALOHA protocol).
In this second model, we compare five different heuristics, all based on the UCB algorithm, and numerical simulation show that all the non-naive heuristics succeed in significantly improving the network efficiency.
Interestingly, the simpler heuristic is found to be the most efficient one, as its simplicity implies a faster learning and convergence time.


\vfill{}

\paragraph{Publications}

This Chapter is mainly based on the following publications: \cite{Bonnefoi17,Besson2018ICT,Besson2019WCNC,Bonnefoi2019WCNC}.

\newpage
% Write miniTOC just after the title
\graphicspath{{2-Chapters/4-Chapter/Images/}}


% ----------------------------------------------------------------------------
% \section{Motivations for Selfish MAB Learning for IoT Networks}
\section{Introduction}
\label{sec:4:motivations}
% ----------------------------------------------------------------------

We already explained in Chapter~\ref{chapter:1} that
unlicensed bands are more and more used and considered for mobile and LAN communication standards (WiFi, LTE-U), and for Internet of Things (IoT) standards for short-range (ZigBee, Z-Wave, Bluetooth) and long-range (LoRaWAN, SIGFOX, Ingenu, Weightless) communications \cite{Centenaro16}.
This heavy use of unlicensed bands will cause performance drop, and could even compromise IoT promises.

Efficient Medium Access (MAC) policies allow devices to avoid interfering traffic and can significantly reduce the spectrum contention problem in unlicensed bands.
As end-devices battery life is a key constraint of IoT networks,
this leads to IoT protocols using as low signaling overhead as possible and simple ALOHA-based mechanisms.
%
In this Chapter, we analyze the performance of Multi-Armed Bandits (MAB) algorithms, used in combination with a time-frequency slotted ALOHA-based protocol.
We consider the Upper-Confidence Bound (\UCB) \cite{Auer02}, and the Thompson-Sampling (TS) algorithms \cite{Thompson33,AgrawalGoyal11,
Kaufmann12Thompson}, for the first model. For the demonstration as well as for the second model, we preferred to focus on heuristics based on the simplest algorithm (\ie, \UCB), to give a clear presentation of the different ideas explored for solve the problem of learning in order to retransmit efficiently.

As detailed in Chapter~\ref{chapter:1},
MAB learning has already been proposed in Cognitive Radio (CR) \cite{Haykin05}, and in particular, for sensing-based Dynamic Spectrum Access (DSA) in licensed bands \cite{Jouini10}.
% For example, \cite{Jouini10} presents the OSA setting, and \cite{Maghsudi16} shows how MAB learning can be applied for small cell management in licensed 5G networks.
Recently, TS and \UCB{} algorithms have been used for improving the spectrum access in (unlicensed) WiFi networks, for instance by \cite{Toldov16} or \cite{Wilhelmi19collaborative,Wilhelmi19potential}.
Many recent works show that stationary MAB algorithms work well for real-world radio signal.
However, even with only one dynamic user using the learning algorithm, the background traffic or the traffic of the other devices is never really stationary or \iid{}.

We present in Section~\ref{sec:4:firstModel} how the MAB algorithms can be used in a unlicensed but frequency- and time-slotted IoT network.
Several devices are using bandit algorithms, and the assumptions made by the stochastic bandit algorithms are not satisfied: as several agents learn simultaneously and their activation processes are random, their behavior is not stationary.
As far as we know, we provide the first study to confirm robustness of the use of stochastic bandit algorithms for decision making in IoT networks with a large number of intelligent devices in the network, which makes the environment ``highly'' not stationary, making it very hard to give mathematical proofs of  convergence and efficiency for bandit algorithms.
We then validate the model with a hardware implementation on real radio signals, detailed in Section~\ref{sec:4:gnuradio}.
%
We conclude this Chapter by presenting in Section~\ref{sec:4:retransmissions} an extension of this model to take into account another aspect of the ALOHA protocol, that is the possibility for dynamic devices to retransmit their packet if the \emph{Ack} was not received.


% ----------------------------------------------------------------------------
\section[Selfish learning for many dynamic devices in an IoT network]{Selfish learning for many dynamic devices with low activation probabilities in an IoT network}
\label{sec:4:firstModel}
% ----------------------------------------------------------------------

% - ``Multi-Armed Bandit Learning in IoT Networks and non-stationary settings'', see https://hal.inria.fr/hal-01575419

\input{2-Chapters/4-Chapter/CrownCom_17.git/IoT_slotted.tex}


% ----------------------------------------------------------------------------
\section{Test-bed implementation of our model for real-world validation}
\label{sec:4:gnuradio}
% ----------------------------------------------------------------------

% - ``MALIN: Multi-Arm bandit Learning for Iot Networks with GRC: A TestBed Implementation and Demonstration that Learning Helps'', demo at ICT, and the companion paper ``GNU Radio Implementation of MALIN: "Multi-Armed bandits Learning for Internet-of-things Network"'', see https://hal.inria.fr/hal-02006825

\input{2-Chapters/4-Chapter/IEEE_WCNC_2019__DemoICT.git/main.tex}



% ----------------------------------------------------------------------------
\section{Extension of our model to account for retransmissions}
\label{sec:4:retransmissions}
% ----------------------------------------------------------------------

% - ``Upper-Confidence Bound for Channel Selection in LPWA Networks with Retransmissions'', see \texttt{https://perso.crans.org/besson/articles/BMBM\_\_IEEE\_WCNC\_2019.pdf}

\input{2-Chapters/4-Chapter/IEEE_WCNC__2019__Paper__BMBM.git/IEEE_WCNC__2019__Paper__BMBM.tex}


% ----------------------------------------------------------------------------
\section{Conclusion}
\label{sec:4:conclusion}
% ----------------------------------------------------------------------

We give in this Section conclusions about the two models presented above and about our demonstration, as well as many directions of future works, some of which are currently being studied by researchers of our team.

\subsection*{Conclusions}

% ----------------------------------------------------------------------
\paragraph{Summary of the first model}
\label{sub:41:conclusion}

In Section~\ref{sec:4:firstModel}, we proposed an evaluation of the performance of MAB learning algorithms in IoT networks,
with a focus on the convergence of algorithms, in terms of successful transmission rates, when the proportion of intelligent dynamic devices changes.
Concretely, increasing this probability allows to insert more objects in the same network, while maintaining a good Quality of Service.
We show that \UCB{} and TS have near-optimal performance, even when their underlying \iid{} assumption is violated by the presences many ``intelligent'' end-devices which follow a random activation process.

This is both a surprising and a very encouraging result, showing that application of bandit algorithms tailored for a stochastic model is still useful in broader settings.
The fully \emph{decentralized} application of classic stochastic MAB algorithms are almost as efficient as the best possible centralized policy in this setting, after a short learning period, even though the dynamic devices \emph{can not} communicate with each others, and \emph{do not} know the system parameters.


% ----------------------------------------------------------------------
\paragraph{Conclusions taken from the demonstration}
\label{sub:42:conclusionFromDemonstration}

We presented in Section~\ref{sec:4:gnuradio} a demonstration, showed in $2018$ at the ICT conference \cite{Besson2018ICT}, and further detailed in the companion paper \cite{Besson2019WCNC}.
We gave all the necessary details on both the PHY and the MAC layer, as well as details on the User Interface developed for the demo.
Results obtained in practice were discussed, to highlight the interest of using learning algorithms for radio online optimization problem, and especially multi-armed bandit learning algorithms.
%
By using such low-cost algorithms, we demonstrated empirically that a dynamically re-configurable object can learn on its own to favor a certain channel, if the environment traffic is not uniform between the $K$ different channels, by using the acknowledgement (\Ack) feedback sent from the base station.


% ----------------------------------------------------------------------
\paragraph{Conclusion about this second model}
\label{sub:43:conclusion}

In Section~\ref{sec:4:retransmissions}, we presented an extension of our model of LPWA networks based on an ALOHA protocol, slotted both in time and frequency, in which dynamic IoT devices can again use machine learning algorithms, to improve their Packet Loss Ratio (PLR) when accessing the network.
The main novelty of this model is to address the packet retransmissions upon radio collision, by using a Multi-Armed Bandit framework.
We presented and evaluated several learning heuristic that try to learn how to transmit and retransmit in a smarter way, by using the \UCB{} algorithm for channel selection for first transmission, and different proposals based on \UCB{} for the retransmissions upon collisions.

We showed that incorporating learning for the transmission is needed to achieve optimal performance, with significant gain in terms of successful transmission rate in networks with a large number of devices (up-to $30\%$ in the example network).
Our empirical simulations show that each of our proposed heuristic outperforms a naive random access scheme.
Surprisingly, the main take-away message is that a simple \UCB{} learning approach, that retransmit in the same channel, turns out to perform as well as more complicated heuristics.


% ----------------------------------------------------------------------
\subsection*{Future works}
\label{sub:4:futureWorks}

Future works related to this Chapter include the following directions.


\paragraph{Possible extensions of the first model}

The first model presented in Section~\ref{sec:4:firstModel} could easily be generalized with two probabilities $p_S$ and $p_D$, if static and dynamic devices had different transmission pattern, and less easily with one probability per device. Also, other emission pattern could be considered, instead of a Bernoulli process for each user.
In this whole Chapter~\ref{chapter:4}, we prefer to consider that all devices have the same activation probability, to keep the notation as simple as possible.

Moreover, for sake of simplicity we supposed that all devices use the same standard.
Future works could consider more realistic interference scenarios and IoT networks, with, \eg, non-slotted time, more than one base station etc.

Another extension could be to not have a Bernoulli process (or any random process), but a fixed rate of transmission, \eg, one transmission a day.
So additionally to deciding the channel for communication (\ie, \emph{where} to communicate), each device has to also decide \emph{when} to communicate.
% This is another direction of research, that we will investigate in the future.
However, this clearly leads to a much larger action space, as there are many time slots in one day (for example), and thus we believe that as soon as the action space becomes too large in this extension, the simple MAB-based learning approach could be no longer appropriate.
It is well-known in the MAB literature that the larger the action space, the slower is the convergence speed of any stationary MAB algorithms.
It could be interesting to study the possible application of \emph{contextual} MAB \cite{Li10,Luo17} or structured MAB \cite{Combes17} models and algorithms for this extension.

% We will investigate this behavior in order to understand it better theoretically.
% We will also experiment more with adversarial algorithms, to confirm that they work less efficiently than stochastic bandit algorithms in our non-stochastic setting.

\paragraph{Extensions of the demonstration}

Possible future extensions of our demonstration include the following points.
We could consider more dynamic objects (\eg, $100$) but it would either cost more in terms of equipment, or in terms of software engineering to simulation more objects with the same card.
We could also implement a real-world IoT communication protocol (like the LoRaWAN standard), which we prefer not to do as it would cost a significant effort of development.
Finally, we could also study the interference in case of other gateways located nearby, and this could be done without needing a lot of new hardware (using one extra USRP card is enough to simulate another gateway).
%
% Pub pour notre autre article
% We are also interested in studying the possible gain of using a learning step when the transmission model follows ALOHA-like retransmissions, and this is presented in the next Section~\ref{sec:4:retransmissions}.


\paragraph{Possible extensions for the second model}

The utility and impact of the proposed approaches for LPWA networks motivates us to address several subjects as future works. Among them, the non-stationarity of the channel occupancy caused by the learning policy employed by the IoT devices.
%
For that end, modifications of MAB algorithms have been proposed, such as Sliding-Window-\UCB{} or Discounted-\UCB{} \cite{Garivier11UCBDiscount}
or more recently M-\UCB{} \cite{CaoZhenKvetonXie18},
or more recently GLR-\UCB{} \cite{Besson2019GLRT} which is presented in Chapter~\ref{chapter:6},
that nevertheless have not been explored for the targeted problem.
Chapter~\ref{chapter:6} is focusing on this direction, but we did not have enough time to explore the possible applications of MAB policies designed for non-stationary problems to the model with retransmissions presented in this Chapter.

In order to validate our results in a realistic experimental setting and not only with simulations, future works include a hardware implementation of the analyzed models to complete our demonstration \cite{Besson2019WCNC}.
Note that Julio César Mango-Vasquez is currently working on this direction, for the EPHYL project, in collaboration with Carlos Faouzi Bader at IETR and CentraleSupélec campus of Rennes, and Christophe Moy at IETR and University Rennes 1.
%
A hardware demonstrator could be also benefit to study other settings by removing some hypotheses, for instance by studying a similar model in non-slotted time.


\newpage
% ----------------------------------------------------------------------------
\section{Appendix}
\label{sec:4:appendix}
% \section{Proof of Proposition \ref{prop:41:Lagrangian}}
\label{sec:5:proofLagrangian}
% ----------------------------------------------------------------------------

% We include here a missing proof from Section~\ref{sec:4:firstModel}.

\input{2-Chapters/4-Chapter/CrownCom_17.git/IoT_slotted_appendix.tex}
