%!TEX root = ../PhD_thesis__Lilian_Besson

% ----------------------------------------------------------------------
\chapter{More Efficient Spectrum Usage of IoT Networks with Selfish MAB Learning}
\label{chapter:4}
\minitoc
% ----------------------------------------------------------------------

In this Chapter~\ref{chapter:4}, we present two models of Internet of Things networks, composed of many independent devices that are able to run MAB algorithm to learn and improve their access to the network.
The two models are presented mathematically, and numerical simulations justify the interest of the proposed algorithms.
We also present a proof-of-concept real-world validation of the advantage of using Multi-Armed Bandit algorithms for the first model, by showing and explaining a demonstration implemented on USRP \cite{USRPDocumentation} cards.

More precisely, on the one hand, we start by presenting in Section~\ref{sec:4:firstModel} a model where independent devices use an IoT network composed of different channels, used by static devices.
Devices do not use any sensing, but use acknowledgements sent by the Base Station to know if their communication messages were successfully received.
We consider the case when many independent ``dynamic'' devices all have a small probability of communicating at every discrete time. If they use simple MAB algorithms in a decentralized and independent fashion (what we call ``selfish'' learning),
we show in simulations that in the case of non-uniform repartition of static devices in the channels, the dynamic devices can improve a lot the network efficiency.
%
On a simple example, we present in Section~\ref{sec:4:gnuradio} a demonstration that implements and validates the proposed approach, using real radio hardware.

On the other hand, we present in Section~\ref{sec:4:retransmissions} a second model extending the first one, when devices can retransmit their messages for a fixed number of maximum retransmission (like in the ALOHA protocol).
In this second model, we compare different heuristic, all based on the UCB algorithm, and numerical simulation show that all the non-naive heuristics succeed in significantly improving the network efficiency.

\newpage
% Write miniTOC just after the title
\graphicspath{{2-Chapters/4-Chapter/Images/}}


% ----------------------------------------------------------------------------
\section{Motivations for Selfish MAB Learning for IoT Networks}
\label{sec:4:motivations}
% ----------------------------------------------------------------------

Unlicensed bands are more and more used and considered for mobile and LAN communication standards (WiFi, LTE-U), and for Internet of Things (IoT) standards for short-range (ZigBee, Z-Wave, Bluetooth) and long-range (LoRaWAN, SIGFOX, Ingenu, Weightless) communications \cite{Centenaro16}.
This heavy use of unlicensed bands will cause performance drop, and could even compromise IoT promises.

Efficient Medium Access (MAC) policies allow devices to avoid interfering traffic and can significantly reduce the spectrum contention problem in unlicensed bands.
As end-devices battery life is a key constraint of IoT networks,
this leads to IoT protocols using as low signaling overhead as possible and simple ALOHA-based mechanisms.
%
In this Section, we analyze the performance of Multi-Armed Bandits (MAB) algorithms, used in combination with a time-frequency slotted ALOHA-based protocol.
We consider the Upper-Confidence Bound (\UCB) \cite{Auer02}, and the Thompson-Sampling (TS) algorithms \cite{Thompson33,AgrawalGoyal11,
Kaufmann12Thompson}.

MAB learning has already been proposed in Cognitive Radio (CR) \cite{Haykin05}, and in particular, for sensing-based Dynamic Spectrum Access (DSA) in licensed bands \cite{Jouini10}.
For example, \cite{Jouini10} presents the OSA setting, and \cite{Maghsudi16} shows how MAB learning can be applied for small cell management in licensed 5G networks.
Recently, TS and \UCB{} algorithms have been used for improving the spectrum access in (unlicensed) WiFi networks \cite{Toldov16}, and the \UCB{} algorithm was used in a unlicensed and frequency- and time-slotted IoT network \cite{Bonnefoi17}.
Many recent works show that MAB algorithms work well for real-world radio signal.
However, even with only one dynamic user using the learning algorithm, the background traffic or the traffic of the other devices is never really stationary or \iid{}.
In recent works like \cite{Bonnefoi17}, several devices are using bandit algorithms, and the assumptions made by the stochastic bandit algorithms are not satisfied: as several agents learn simultaneously, their behavior is neither stationary nor \iid.
As far as we know, we provide the first study to confirm robustness of the use of stochastic bandit algorithms for decision making in IoT networks with a large number of intelligent devices in the network, which makes the environment not stationary at all, violating the hypothesis required for mathematical proofs of bandit algorithms convergence and efficiency.

We also present an extension of this model to take into account another aspect of the ALOHA protocol, that is the possibility for dynamic devices to retransmit their packet if the \emph{Ack} was not received.

% \TODOL{Present outline of the chapter.}

\paragraph{Publications}

This Chapter is based on the following publications: \cite{Bonnefoi17,Besson2018ICT,Besson2019WCNC,Bonnefoi2019WCNC}.


% ----------------------------------------------------------------------------
\section{Selfish learning for many dynamic devices with low activation probabilities in an IoT network}
\label{sec:4:firstModel}
% ----------------------------------------------------------------------

% - ``Multi-Armed Bandit Learning in IoT Networks and non-stationary settings'', see https://hal.inria.fr/hal-01575419

\input{2-Chapters/4-Chapter/CrownCom_17.git/IoT_slotted.tex}


% ----------------------------------------------------------------------------
\section{Test-bed implementation of our model for real-world validation}
\label{sec:4:gnuradio}
% ----------------------------------------------------------------------

% - ``MALIN: Multi-Arm bandit Learning for Iot Networks with GRC: A TestBed Implementation and Demonstration that Learning Helps'', demo at ICT, and the companion paper ``GNU Radio Implementation of MALIN: "Multi-Armed bandits Learning for Internet-of-things Network"'', see https://hal.inria.fr/hal-02006825

\input{2-Chapters/4-Chapter/IEEE_WCNC_2019__DemoICT.git/main.tex}



% ----------------------------------------------------------------------------
\section{Extension of our model to account for retransmissions}
\label{sec:4:retransmissions}
% ----------------------------------------------------------------------

% - ``Upper-Confidence Bound for Channel Selection in LPWA Networks with Retransmissions'', see \texttt{https://perso.crans.org/besson/articles/BMBM\_\_IEEE\_WCNC\_2019.pdf}

\input{2-Chapters/4-Chapter/IEEE_WCNC__2019__Paper__BMBM.git/IEEE_WCNC__2019__Paper__BMBM.tex}


% ----------------------------------------------------------------------------
\section{Conclusion of Chapter~\ref{chapter:4}}
\label{sec:4:conclusion}
% ----------------------------------------------------------------------

We give in this Section conclusions about the two models presented above and about our demonstration, as well as many directions of future works, some of which are currently being studied by researchers of our team.


% ----------------------------------------------------------------------
\paragraph{Summary of the first model}
\label{sub:41:conclusion}

In Section~\ref{sec:4:firstModel}, we proposed an evaluation of the performance of MAB learning algorithms in IoT networks,
with a focus on the convergence of algorithms, in terms of successful transmission rates, when the proportion of intelligent dynamic devices changes.
Concretely, increasing this probability allows to insert more objects in the same network, while maintaining a good Quality of Service.
We show that \UCB{} and TS have near-optimal performance, even when their underlying \iid{} assumption is violated by the many ``intelligent'' end-devices.

This is both a surprising and a very encouraging result, showing that application of bandit algorithms tailored for a stochastic model is still useful in broader settings.
The fully \emph{decentralized} application of classic stochastic MAB algorithms are almost as efficient as the best possible centralized policy in this setting, after a short learning period, even though the dynamic devices \emph{can not} communicate with each others, and \emph{do not} know the system parameters.
We will investigate this behavior in order to understand it better theoretically.
We will also experiment more with adversarial algorithms, to confirm that they work less efficiently than stochastic bandit algorithms in our non-stochastic setting.


% ----------------------------------------------------------------------
\paragraph{Conclusions taken from the demonstration}
\label{sub:42:conclusionFromDemonstration}

We presented in Section~\ref{sec:4:gnuradio} a demonstration, showed in $2018$ at the ICT conference \cite{Besson2018ICT}, and further detailed in the companion paper \cite{Besson2019WCNC}.
We gave all the necessary details on both the PHY and the MAC layer, as well as details on the User Interface developed for the demo.
Results obtained in practice were discussed, to highlight the interest of using learning algorithms for radio online optimization problem, and especially multi-armed bandit learning algorithms.
%
By using such low-cost algorithms, we demonstrated empirically that a dynamically reconfigurable object can learn on its own to favor a certain channel, if the environment traffic is not uniform between the $K$ different channels.


% ----------------------------------------------------------------------
\paragraph{Conclusion about this second model}
\label{sub:43:conclusion}

In Section~\ref{sec:4:retransmissions}, we presented an extension of our model of LPWA networks based on an ALOHA protocol, slotted both in time and frequency, in which dynamic IoT devices can use machine learning algorithms, to improve their Packet Loss Ratio (PLR) when accessing the network.
The main novelty of this model is to address the packet retransmissions upon radio collision, by using a Multi-Armed Bandit framework.
We presented and evaluated several learning heuristic that try to learn how to transmit and retransmit in a smarter way, by using the \UCB{} algorithm for channel selection for first transmission, and different proposals based on \UCB{} for the retransmissions upon collisions.

We showed that incorporating learning for the transmission is needed to achieve optimal performance, with significant gain in terms of successful transmission rate in networks with a large number of devices (up-to $30\%$ in the example network).
Our empirical simulations show that each of our proposed heuristic outperforms a naive random access scheme.
Surprisingly, the main take-away message is that a simple \UCB{} learning approach, that retransmit in the same channel, turns out to perform as well as more complicated heuristics.


% ----------------------------------------------------------------------
\paragraph{Future works}
\label{sub:4:futureWorks}

Future works related to this Chapter include the following directions.


\paragraph{Possible extensions of the first model}

The first model presented in Section~\ref{sec:4:firstModel} could easily be generalized with two probabilities $p_S$ and $p_D$, if static and dynamic devices had different transmission pattern, and less easily with one probability per device. Also, other emission pattern could be considered, instead of a Bernoulli process for each user.
We prefer to consider that all devices have the same probability to transmit to keep the notation as simple as possible.

Moreover, for sake of simplicity we supposed that all devices use the same standard. Our future work will consider more realistic interference scenarios and IoT networks, with, \emph{e.g.}, non-slotted time, more than one base station etc.

Another extension could be to not have a Bernoulli process (or any random process), but a fixed rate of transmission, \emph{e.g.}, one transmission a day.
So additionally to deciding the channel for communication, each device has to also decide when to communicate.
This is another direction of research, that we will investigate in the future.

\paragraph{Extensions of the demonstration}

Possible future extensions of our demonstration include the following points.
We could consider more dynamic objects (\emph{e.g.}, $100$) but it would either cost more in terms of equipment, or in terms of software engineering to simulation more objects with the same card.
We could also implement a real-world IoT communication protocol (like the LoRaWAN standard), which we prefer not to do as it would cost a significant effort of development.
Finally, we could also study the interference in case of other gateways located nearby, and this could be done without needing new hardware.
%
% Pub pour notre autre article
% We are also interested in studying the possible gain of using a learning step when the transmission model follows ALOHA-like retransmissions, and this is presented in the next Section~\ref{sec:4:retransmissions}.


\paragraph{Possible extensions for the second model}

The utility and impact of the proposed approaches for LPWA networks motivates us to address several subjects as future works. Among them, the non-stationarity of the channel occupancy caused by the learning policy employed by the IoT devices.
%
For that end, modifications of MAB algorithms have been proposed, such as Sliding-Window-\UCB{} or Discounted-\UCB{} \cite{Garivier11UCBDiscount}
or more recently M-\UCB{} \cite{CaoZhenKvetonXie18},
or more recently GLR-\UCB{} \cite{Besson2019GLRT} which is presented in Chapter~\ref{chapter:6},
that nevertheless have not been explored for the targeted problem.
Chapter~\ref{chapter:6} is focusing on this direction, but we did not have enough time to explore the possible applications of MAB policies designed for non-stationary problems to the model with retransmissions presented in this section.

In order to validate our results in a realistic experimental setting and not only with simulations, future works include a hardware implementation of the analyzed models to complete our demonstration \cite{Besson2019WCNC}.
Note that Julio César Mango-Vasquez is currently working on this direction, for the EPHYL project, in collaboration with Carlos Faouzi Bader at IETR and CentraleSupélec campus of Rennes, and Christophe Moy at IETR and University Rennes 1.
%
A hardware demonstrator could be also benefit to study other settings by removing some hypotheses, for instance by studying a similar model in non-slotted time.


% ----------------------------------------------------------------------------
\section{Appendix for Chapter~\ref{chapter:4}}
\label{sec:4:appendix}
% ----------------------------------------------------------------------------

We include here a missing proof from Section~\ref{sec:4:firstModel}.

\input{2-Chapters/4-Chapter/CrownCom_17.git/IoT_slotted_appendix.tex}
